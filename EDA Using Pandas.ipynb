{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be1d788a",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "## Data Engineering Capstone Project\n",
    "## Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d580062c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'importlib.reload(utility)\\nfrom utility import visualise_missing_values, clean_immigration, clean_temperature_data\\nfrom utility import clean_demographics_data'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import configparser\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import utility\n",
    "\n",
    "import importlib\n",
    "\"\"\"importlib.reload(utility)\n",
    "from utility import visualise_missing_values, clean_immigration, clean_temperature_data\n",
    "from utility import clean_demographics_data\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f30b14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('config.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5fcd76",
   "metadata": {},
   "source": [
    "## Step 1: Scope the Project and Gather Data\n",
    "### Scope\n",
    "---\n",
    "The objective of this project is to develop a cloud-based data warehouse solution that will provide decision and policy makers with an analytics database for immigration and toursim related data. A use case of this analytics database is to power dashboards and visualizations that assist organisations such as the National Travel & Tourism Office (NTTO) in it's quest to create a positive climate for growth in travel and tourism through reducing institutional barriers to tourism.\n",
    "\n",
    "The technology used in this project is Amazon S3, Amazon Redshift, Apache Spark and Apache Airflow. Data will be read and staged from the customers repository to S3 using Spark. Scheduled monthly jobs will be run using Apache Airflow to populate a data warehouse on RedShift."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e326f1",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "---\n",
    "Describe the data sets you're using. Where did it come from? What type of information is included?\n",
    "\n",
    "### World Temperature Data\n",
    "* This dataset came from Kaggle.\n",
    "### U.S. City Demographic Data\n",
    "* This data comes from OpenSoft.\n",
    "### Airport Code Table\n",
    "* This is a simple table of airport codes and corresponding cities.\n",
    "\n",
    "### Technology\n",
    "\n",
    "### Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4122723",
   "metadata": {},
   "source": [
    "### Immigration Data: Data Description\n",
    "---\n",
    "This data comes from the US National Tourism and Trade Office. In the past all foreign visitors to the U.S. arriving via air or sea were required to complete paper Customs and Border Protection Form I-94 Arrival/Departure Record or Form I-94W Nonimmigrant Visa Waiver Arrival/Departure Record and this dataset comes from this forms.\n",
    "\n",
    "This dataset forms the core of the data warehouse and the customer repository has a years worth of data for the year 2016 and the dataset is divided by month. For this project the data is in a folder located at ../../data/18-83510-I94-Data-2016/. Each months data is stored in an SAS binary database storage format sas7bdat. For this project we have chosen going to work with data for the month of April. However, the data extraction, transformation and loading utility functions have been designed to work with any month's worth of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa63a20",
   "metadata": {},
   "source": [
    "<b><i>Data dictionary</i></b>\n",
    "\n",
    "|Feature|Description|\n",
    "|:--|:--|\n",
    "|cicid|Unique record ID|\n",
    "|i94yr|4 digit year|\n",
    "|i94mon|Numeric month|\n",
    "|i94cit|3 digit code for immigrant country of birth|\n",
    "|i94res|3 digit code for immigrant country of residence|\n",
    "|i94port|Port of admission|\n",
    "|arrdate|Arrival Date in the USA|\n",
    "|i94mode|Mode of transportation (1 = Air; 2 = Sea; 3 = Land; 9 = Not reported)|\n",
    "|i94addr|USA State of arrival|\n",
    "|depdate|Departure Date from the USA|\n",
    "|i94bir|Age of Respondent in Years|\n",
    "|i94visa|Visa codes collapsed into three categories|\n",
    "|count|Field used for summary statistics|\n",
    "|dtadfile|Character Date Field - Date added to I-94 Files|\n",
    "|visapost|Department of State where where Visa was issued|\n",
    "|occup|Occupation that will be performed in U.S|\n",
    "|entdepa|Arrival Flag - admitted or paroled into the U.S.|\n",
    "|entdepd|Departure Flag - Departed, lost I-94 or is deceased|\n",
    "|entdepu|Update Flag - Either apprehended, overstayed, adjusted to perm residence|\n",
    "|matflag|Match flag - Match of arrival and departure records|\n",
    "|biryear|4 digit year of birth|\n",
    "|dtaddto|Character Date Field - Date to which admitted to U.S. (allowed to stay until)|\n",
    "|gender|Non-immigrant sex|\n",
    "|insnum|INS number|\n",
    "|airline|Airline used to arrive in U.S.|\n",
    "|admnum|Admission Number|\n",
    "|fltno|Flight number of Airline used to arrive in U.S.|\n",
    "|visatype|Class of admission legally admitting the non-immigrant to temporarily stay in U.S.|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6f03ad",
   "metadata": {},
   "source": [
    "#### Load I94 Immigration dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b609b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ps/_h4yrbcj389fq3z_h2sh3cl00000gq/T/ipykernel_80321/2186393529.py:3: FutureWarning: In a future version of pandas all arguments of read_sas except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  df = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")\n"
     ]
    }
   ],
   "source": [
    "# Read in the data here - stored in dataset folder\n",
    "fname = 'dataset/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "df = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d345496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate  ...  entdepu  matflag  biryear   dtaddto gender insnum airline  \\\n",
       "0      NaN  ...        U      NaN   1979.0  10282016    NaN    NaN     NaN   \n",
       "1      NaN  ...        Y      NaN   1991.0       D/S      M    NaN     NaN   \n",
       "2  20691.0  ...      NaN        M   1961.0  09302016      M    NaN      OS   \n",
       "3  20567.0  ...      NaN        M   1988.0  09302016    NaN    NaN      AA   \n",
       "4  20567.0  ...      NaN        M   2012.0  09302016    NaN    NaN      AA   \n",
       "\n",
       "         admnum  fltno visatype  \n",
       "0  1.897628e+09    NaN       B2  \n",
       "1  3.736796e+09  00296       F1  \n",
       "2  6.666432e+08     93       B2  \n",
       "3  9.246846e+10  00199       B2  \n",
       "4  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a4d8aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/anaconda3/envs/data-lake-aws/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/cian.young/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/cian.young/.ivy2/jars\n",
      "saurfang#spark-sas7bdat added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-6cfdcba7-e188-4c88-9967-0f5f494cfbb9;1.0\n",
      "\tconfs: [default]\n",
      "\tfound saurfang#spark-sas7bdat;3.0.0-s_2.12 in spark-packages\n",
      "\tfound com.epam#parso;2.0.11 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.5 in central\n",
      "\tfound org.apache.logging.log4j#log4j-api-scala_2.12;12.0 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.10 in central\n",
      "\tfound org.apache.logging.log4j#log4j-api;2.13.2 in central\n",
      "downloading https://repos.spark-packages.org/saurfang/spark-sas7bdat/3.0.0-s_2.12/spark-sas7bdat-3.0.0-s_2.12.jar ...\n",
      "\t[SUCCESSFUL ] saurfang#spark-sas7bdat;3.0.0-s_2.12!spark-sas7bdat.jar (181ms)\n",
      "downloading https://repo1.maven.org/maven2/com/epam/parso/2.0.11/parso-2.0.11.jar ...\n",
      "\t[SUCCESSFUL ] com.epam#parso;2.0.11!parso.jar (53ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/logging/log4j/log4j-api-scala_2.12/12.0/log4j-api-scala_2.12-12.0.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.logging.log4j#log4j-api-scala_2.12;12.0!log4j-api-scala_2.12.jar(bundle) (144ms)\n",
      "downloading https://repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.12.10/scala-reflect-2.12.10.jar ...\n",
      "\t[SUCCESSFUL ] org.scala-lang#scala-reflect;2.12.10!scala-reflect.jar (942ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.logging.log4j#log4j-api;2.13.2!log4j-api.jar (87ms)\n",
      ":: resolution report :: resolve 3974ms :: artifacts dl 1413ms\n",
      "\t:: modules in use:\n",
      "\tcom.epam#parso;2.0.11 from central in [default]\n",
      "\torg.apache.logging.log4j#log4j-api;2.13.2 from central in [default]\n",
      "\torg.apache.logging.log4j#log4j-api-scala_2.12;12.0 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.10 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.5 from central in [default]\n",
      "\tsaurfang#spark-sas7bdat;3.0.0-s_2.12 from spark-packages in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   6   |   5   |   5   |   0   ||   6   |   5   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-6cfdcba7-e188-4c88-9967-0f5f494cfbb9\n",
      "\tconfs: [default]\n",
      "\t5 artifacts copied, 1 already retrieved (4284kB/16ms)\n",
      "23/04/01 13:55:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/04/01 13:55:29 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/04/01 13:55:29 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:3.0.0-s_2.12\")\\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958c02ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"spark = SparkSession.builder\\\n",
    "                    .config(\"spark.jars\",\"https://repo1.maven.org/maven2/com/epam/parso/2.0.8/parso-2.0.8.jar,https://repos.spark-packages.org/saurfang/spark-sas7bdat/2.0.0-s_2.11/spark-sas7bdat-2.0.0-s_2.11.jar\")\\\n",
    "                    .config(\"spark.jars.packages\",\"org.apache.hadoop:hadoop-aws:2.7.0\")\\\n",
    "                    .enableHiveSupport()\\\n",
    "                    .getOrCreate()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aa3fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"spark = SparkSession.builder \\\n",
    "    .config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.1.0-s_2.11,com.epam:parso:2.0.11\") \\\n",
    "    .getOrCreate()\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8fea828",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark =spark.read.format('com.github.saurfang.sas.spark').load('dataset/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5e0a554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ea4d437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/01 13:56:25 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c75d2603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/01 13:57:58 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/04/01 13:57:58 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/04/01 13:57:58 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 75.08% for 9 writers\n",
      "23/04/01 13:57:58 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 67.58% for 10 writers\n",
      "23/04/01 13:57:58 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 61.43% for 11 writers\n",
      "23/04/01 13:57:58 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 56.31% for 12 writers\n",
      "23/04/01 13:57:58 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 51.98% for 13 writers\n",
      "23/04/01 13:57:58 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 48.27% for 14 writers\n",
      "23/04/01 13:58:05 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 51.98% for 13 writers\n",
      "23/04/01 13:58:05 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 56.31% for 12 writers\n",
      "23/04/01 13:58:05 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 61.43% for 11 writers\n",
      "23/04/01 13:58:05 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 67.58% for 10 writers\n",
      "23/04/01 13:58:05 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 75.08% for 9 writers\n",
      "23/04/01 13:58:05 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/04/01 13:58:05 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#write to parquet\n",
    "df_spark.write.parquet(\"sas_data_1\")\n",
    "df_spark=spark.read.parquet(\"sas_data_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46206c85",
   "metadata": {},
   "source": [
    "### World Temperature Data: Data Description\n",
    "---\n",
    "The World Temperature dataset comes from Kaggle and represents global land temperatures by city.\n",
    "\n",
    "Load World Temperature dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "799ccc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'data/GlobalLandTemperaturesByCity.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c046db87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wt = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3ce7e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Peek at the data\n",
    "df_wt.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d3aa45",
   "metadata": {},
   "source": [
    "#### Data dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b335fd73",
   "metadata": {},
   "source": [
    "| Feature | Description |\n",
    "| --- | --- |\n",
    "| dt | Date |\n",
    "| AverageTemperature | Global average land temperature in celsius |\n",
    "| AverageTemperatureUncertainty | 95% confidence interval around the average |\n",
    "| City | Name of City |\n",
    "| Country | Name of Country |\n",
    "| Latitude | City Latitude |\n",
    "| Longitude | City Longitude |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36ac885f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8599212, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2c5b86",
   "metadata": {},
   "source": [
    "### U.S. City Demographic Data: Data Description\n",
    "---\n",
    "This data comes from OpenSoft and contains information about the demographics of all US cities and census-designated places with a population greater or equal to 65,000. Original data comes from the US Census Bureau's 2015 American Community Survey.\n",
    "\n",
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98c1d804",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cd = pd.read_csv('data/us-cities-demographics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f59a7386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2891, 12)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38596316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City          State  Median Age  Male Population  \\\n",
       "0  Silver Spring       Maryland        33.8          40601.0   \n",
       "1         Quincy  Massachusetts        41.0          44129.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "\n",
       "   Average Household Size State Code                Race  Count  \n",
       "0                    2.60         MD  Hispanic or Latino  25924  \n",
       "1                    2.39         MA               White  58723  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cd.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b33d5a",
   "metadata": {},
   "source": [
    "#### Data dictionary\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| City | City Name |\n",
    "| State | US State where city is located |\n",
    "| Median Age | Median age of the population |\n",
    "| Male Population | Count of male population |\n",
    "| Female Population | Count of female population |\n",
    "| Total Population | Count of total population |\n",
    "| Number of Veterans | Count of total Veterans |\n",
    "| Foreign born | Count of residents of the city that were not born in the city |\n",
    "| Average Household Size | Average city household size |\n",
    "| State Code | Code of the US state |\n",
    "| Race | Respondent race |\n",
    "| Count | Count of city's individual per race |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c6e0f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2891, 12)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a253a8a",
   "metadata": {},
   "source": [
    "## Step 2: Explore and Assess the Data\n",
    "### Explore the Data\n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "### Cleaning Steps\n",
    "Document steps necessary to clean the data\n",
    "\n",
    "### EDA Immigration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a772a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i94_nov16_sub.sas7bdat',\n",
       " 'i94_dec16_sub.sas7bdat',\n",
       " 'i94_sep16_sub.sas7bdat',\n",
       " 'i94_aug16_sub.sas7bdat',\n",
       " 'i94_may16_sub.sas7bdat',\n",
       " 'i94_jun16_sub.sas7bdat',\n",
       " 'i94_oct16_sub.sas7bdat',\n",
       " 'i94_apr16_sub.sas7bdat',\n",
       " 'i94_jan16_sub.sas7bdat',\n",
       " 'i94_jul16_sub.sas7bdat',\n",
       " 'i94_mar16_sub.sas7bdat',\n",
       " 'i94_feb16_sub.sas7bdat']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list all files in the customer repository\n",
    "files = os.listdir('dataset/18-83510-I94-Data-2016/')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e465137",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ps/_h4yrbcj389fq3z_h2sh3cl00000gq/T/ipykernel_80321/1463050319.py:3: FutureWarning: In a future version of pandas all arguments of read_sas except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  df = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")\n"
     ]
    }
   ],
   "source": [
    "# Read in the data for April 2016\n",
    "fname = 'dataset/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "df = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "271ba633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3096313, 28)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see dataframe dimensions\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68381382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate  ...  entdepu  matflag  biryear   dtaddto gender insnum airline  \\\n",
       "0      NaN  ...        U      NaN   1979.0  10282016    NaN    NaN     NaN   \n",
       "1      NaN  ...        Y      NaN   1991.0       D/S      M    NaN     NaN   \n",
       "2  20691.0  ...      NaN        M   1961.0  09302016      M    NaN      OS   \n",
       "3  20567.0  ...      NaN        M   1988.0  09302016    NaN    NaN      AA   \n",
       "4  20567.0  ...      NaN        M   2012.0  09302016    NaN    NaN      AA   \n",
       "\n",
       "         admnum  fltno visatype  \n",
       "0  1.897628e+09    NaN       B2  \n",
       "1  3.736796e+09  00296       F1  \n",
       "2  6.666432e+08     93       B2  \n",
       "3  9.246846e+10  00199       B2  \n",
       "4  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first five rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c01cef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ps/_h4yrbcj389fq3z_h2sh3cl00000gq/T/ipykernel_80321/1333583578.py:5: FutureWarning: In a future version of pandas all arguments of read_sas except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  df_f =  pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/18-83510-I94-Data-2016/i94_nov16_sub.sas7bdat df.shape =  (2914926, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ps/_h4yrbcj389fq3z_h2sh3cl00000gq/T/ipykernel_80321/1333583578.py:5: FutureWarning: In a future version of pandas all arguments of read_sas except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  df_f =  pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/18-83510-I94-Data-2016/i94_dec16_sub.sas7bdat df.shape =  (3432990, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ps/_h4yrbcj389fq3z_h2sh3cl00000gq/T/ipykernel_80321/1333583578.py:5: FutureWarning: In a future version of pandas all arguments of read_sas except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  df_f =  pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/18-83510-I94-Data-2016/i94_sep16_sub.sas7bdat df.shape =  (3733786, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ps/_h4yrbcj389fq3z_h2sh3cl00000gq/T/ipykernel_80321/1333583578.py:5: FutureWarning: In a future version of pandas all arguments of read_sas except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  df_f =  pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/18-83510-I94-Data-2016/i94_aug16_sub.sas7bdat df.shape =  (4103570, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ps/_h4yrbcj389fq3z_h2sh3cl00000gq/T/ipykernel_80321/1333583578.py:5: FutureWarning: In a future version of pandas all arguments of read_sas except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  df_f =  pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/18-83510-I94-Data-2016/i94_may16_sub.sas7bdat df.shape =  (3444249, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ps/_h4yrbcj389fq3z_h2sh3cl00000gq/T/ipykernel_80321/1333583578.py:5: FutureWarning: In a future version of pandas all arguments of read_sas except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  df_f =  pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/18-83510-I94-Data-2016/i94_jun16_sub.sas7bdat df.shape =  (3574989, 34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ps/_h4yrbcj389fq3z_h2sh3cl00000gq/T/ipykernel_80321/1333583578.py:5: FutureWarning: In a future version of pandas all arguments of read_sas except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  df_f =  pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/18-83510-I94-Data-2016/i94_oct16_sub.sas7bdat df.shape =  (3649136, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ps/_h4yrbcj389fq3z_h2sh3cl00000gq/T/ipykernel_80321/1333583578.py:5: FutureWarning: In a future version of pandas all arguments of read_sas except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  df_f =  pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat df.shape =  (3096313, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ps/_h4yrbcj389fq3z_h2sh3cl00000gq/T/ipykernel_80321/1333583578.py:5: FutureWarning: In a future version of pandas all arguments of read_sas except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  df_f =  pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/18-83510-I94-Data-2016/i94_jan16_sub.sas7bdat df.shape =  (2847924, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ps/_h4yrbcj389fq3z_h2sh3cl00000gq/T/ipykernel_80321/1333583578.py:5: FutureWarning: In a future version of pandas all arguments of read_sas except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  df_f =  pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/18-83510-I94-Data-2016/i94_jul16_sub.sas7bdat df.shape =  (4265031, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ps/_h4yrbcj389fq3z_h2sh3cl00000gq/T/ipykernel_80321/1333583578.py:5: FutureWarning: In a future version of pandas all arguments of read_sas except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  df_f =  pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/18-83510-I94-Data-2016/i94_mar16_sub.sas7bdat df.shape =  (3157072, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ps/_h4yrbcj389fq3z_h2sh3cl00000gq/T/ipykernel_80321/1333583578.py:5: FutureWarning: In a future version of pandas all arguments of read_sas except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  df_f =  pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/18-83510-I94-Data-2016/i94_feb16_sub.sas7bdat df.shape =  (2570543, 28)\n"
     ]
    }
   ],
   "source": [
    "# be careful with running this cell, will take a long time to execute\n",
    "for name in files:\n",
    "    # read the data into a data frame\n",
    "    fname = 'dataset/18-83510-I94-Data-2016/' + name\n",
    "    df_f =  pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")\n",
    "    print(f'{fname} df.shape = ', df_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1319808c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'visualise_missing_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# lets visualize % missing values per immigration feature\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mvisualise_missing_values\u001b[49m(df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'visualise_missing_values' is not defined"
     ]
    }
   ],
   "source": [
    "# lets visualize % missing values per immigration feature\n",
    "visualise_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf22ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
